---
---

@string{aps = {American Physical Society,}}

@article{BuildNet3D,
  abbr={PAPER},
  title={Exploiting Semantic Scene Reconstruction for Estimating Building Envelope Characteristics},
  author={Xu, C. and Mielle, M. and Laborde, A. and Waseem, A., and Forest, F. and Fink, O.},
  journal={Building and Environment},
  abstract={The precise assessment of geometric building envelope characteristics is essential for informed building retrofitting decisions. Previous methods for estimating building characteristics, such as window-to-wall ratio, building footprint area, and the location of architectural elements, have primarily relied on deep-learning-based detection or segmeantion techniques on 2D images. However, these approaches tend to focus on planar facade properties, limiting their accuracy and comprehensiveness when analyzing 3D building envelopes. This work leverages cutting-edge neural surface reconstruction techniques based on SDF representations for 3D building analysis. We propose BuildNet3D, a novel framework to estimate geometric building characteristics from 2D image inputs. By integrating SDF-based representation with semantic modality, BuildNet3D recovers fine-grained 3D geometry and semantics of building envelopes, enabling the automatic extraction of key building characteristics.},
  year={2025},
  image={buildnet.png},
  publisher=Elsevier,
  arxiv={2410.22383},
  website={https://epfl-imos.github.io/buildnet3d.github.io/},
  selected={true}
}

@article{ChatGarment,
  abbr={PAPER},
  title={ChatGarment: Garment Estimation, Generation and Editing via Large Language Models},
  author={Bian, S. and Xu, C. and Xiu, Y. and Grigorev, A. and Liu, Z. and Lu, C. and Black, M. J. and Feng, Y.},
  journal={Computer Vision & Pattern Recognition Conference (CVPR)},
  abstract={ChatGarment is a novel approach that leverages large vision-language models (VLMs) to automate the estimation, generation, and editing of 3D garment sewing patterns from images or text descriptions. Unlike previous methods that often lack robustness and interactive editing capabilities, ChatGarment finetunes a VLM to produce GarmentCode, a JSON-based, language-friendly format for 2D sewing patterns, enabling both estimating and editing from images and text instructions. To optimize performance, we refine GarmentCode by expanding its support for more diverse garment types and simplifying its structure, making it more efficient for VLM finetuning. Additionally, we develop an automated data construction pipeline to generate a large-scale dataset of image-to-sewing-pattern and text-to-sewing-pattern pairs, empowering ChatGarment with strong generalization across various garment types.},
  year={2025},
  arxiv={2412.17811},
  image={chatgarment.png},
  website={https://chatgarment.github.io/},
  selected={true}
}

@article{DynaPix,
  abbr={PAPER},
  title={DynaPix SLAM: A Pixel-Based Dynamic Visual SLAM Approach},
  author={Xu*, C. and Bonetto*, E. and Ahmad, A.},
  journal={DAGM German Conference on Pattern Recognition (GCPR)},
  abstract={Visual Simultaneous Localization and Mapping (V-SLAM) methods achieve remarkable performance in static environments but struggle with moving objects that affect their core modules. Dynamic SLAM approaches often leverage semantic information, geometric constraints, or optical flow to exclude dynamic elements. However, these methods are limited by imprecise estimations and reliance on the accuracy of deep-learning models. Furthermore, predefined thresholds for static/dynamic classification and the inability to recognize unexpected moving objects also degrade their performance. To address these issues, we introduce DynaPix, a semantic-free SLAM system based on per-pixel motion probability estimation and improved pose optimization. DynaPix estimates per-pixel motion probabilities using a static background differencing method on image data and optical flows from splatted frames, integrating these probabilities into map point selection and applying them through weighted bundle adjustment in ORB-SLAM2. Evaluations on the GRADE and TUM RGB-D datasets demonstrates significantly lower trajectory errors and extended tracking times in both static and dynamic sequences.},
  year={2024},
  publisher=springer,
  arxiv={2309.09879},
  image={dynapix.png},
  code={https://github.com/robot-perception-group/DynaPix},
  website={https://dynapix.is.tue.mpg.de/},
  selected={true}
}

@article{tmech2024,
  abbr={PAPER},
  title={Implementation of a Long-Lasting, Untethered, Lightweight, Upper Limb Exoskeleton},
  author={Liu, H. and Fang, K. and Chen, L. and Xu, C. and Chen, C. and Wang, T. and Wu, Z. and Ye, J. and Fu, C. and Chen, G. and Wang, H.},
  abstract={To prevent muscle fatigue or disorder from long-term or repetitive arm-lifting in manual operations, various exoskeletons have been developed. However, motorized exoskeletons suffer from heavy mass and high cost, while previous passive exoskeletons possess poor adaptability. To solve this problem, we designed a lightweight (3.1 kg) upper limb exoskeleton capable of providing self-adaptable support based on linkage mechanisms and gas springs, with tunable maximum force based on small motors and sensors to adapt to hand loads. The motors adjust the dimension of the mechanical structure, instead of directly supporting the arms, resulting in low power consumption (1.85 W) and extended operation (11 hours). Experimental results show that the measured surface electromyogram activities reduced up to 43.84% and 46.23% for static and dynamic tests, respectively.},
  journal={IEEE/ASME Transactions on Mechatronics (TMECH)},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={2024},
  publisher=ieee,
  image={TMECH.png},
  doi={10.1109/TMECH.2024.3431884},
  html={https://ieeexplore.ieee.org/document/10629199},
  selected={true}
}

@article{IJRR2025,
  abbr={PAPER},
  title={GRADE: Generating Realistic Animated Dynamic Environments for Robotics Research},
  author={Bonetto, E. and Xu, C. and Ahmad, A.},
  abstract={In this work, we present a fully customizable framework for generating realistic animated dynamic environments (GRADE) for robotics research. The data produced can be post-processed, e.g. to add noise, and easily expanded with new information using the tools that we provide. To demonstrate GRADE, we generated an indoor dynamic environment dataset and then compared different SLAM algorithms on the produced sequences. By doing that, we show how current research over-relies on well-known benchmarks and fails to generalize. Furthermore, our tests with YOLO and Mask R-CNN provide evidence that our data can improve training performance and generalize to real sequences. Finally, we show GRADE's flexibility by using it for indoor active SLAM, with diverse environment sources, and in a multi-robot scenario. The code, results, implementation details, and generated data are provided as open-source. },
  journal={arXiv preprint (Under Review)},
  year={2023},
  month={October},
  publisher=aps,
  image={GRADE.jpg},
  arxiv={2303.04466},
  code={https://github.com/robot-perception-group/GRADE_tools/},
  website={https://grade.is.tue.mpg.de/},
  selected={true}
}

@article{FallingWallsLab,
  abbr={ TALK },
  title={Breaking the Wall of Intensive Work Above Head: Design of Passive Upper-Limb Exoskeleton},
  author={Xu, C.},
  abstract={Aiming at various types of jobs like automobile which require long-term arm-lifting work and easily cause muscle damage, a passive adjustable arm-exoskeleton is designed based on a spring slider model and four-bar-linkage model.},
  journal={Falling Walls Lab},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={2019},
  month={November},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  html={https://www.youtube.com/watch?v=olrT6oaLfEA&list=PLkhVBjzvMPh0EPXYHFBxoHLYzbArnXFX1&index=3},
  pdf={lab19.pdf},
  image={fallingwalls.jpg},
  selected={true}
}


@book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein*â€ , A. and Podolsky*, B. and Rosen*, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  annotation={* Example use of superscripts<br>â€  Albert Einstein},
  selected={false}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and SchrÃ¶dinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}
